{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voraussetzungen\n",
    "\n",
    "1. Python 3 Version (getestet mit 3.11.3)\n",
    "2. Installierte Module\n",
    "3. Aggegierte Feature-Daten unter `./data/agg_mapped_data.csv`\n",
    "4. Laufender Datenbank Docker-Container (siehe Abschnitt `12.2.2` in der Arbeit)\n",
    "\n",
    "## Beschreibung\n",
    "\n",
    "Dieses Notebook dient der Simulation von Zugriffen auf Geodaten beziehungsweise auf die Tiles, in welchen diese sich befinden. Der Prozess der Datensynthese\n",
    "ist sehr Rechenaufwendig und hat auf dem Laptop, welcher für die Auswertung benutzt wurde, etwa $11$ Stunden in Anspruch genommen.\n",
    "\n",
    "Das Vorgehen ist wie folgt:\n",
    "\n",
    "1. Verbindung zur Datenbank wird erstellt und POIs werden abgefragt\n",
    "2. Funktionen zur Berechnung der mittleren Zugriffsrate ($\\lambda$) für individuelle POIs\n",
    "3. Einlesen der Feature-Daten\n",
    "4. Funktionalität zur Zuweisung von POI-Koordinaten zu entsprechenden Tiles\n",
    "5. Berechnung von Tile-Zugriffsraten\n",
    "6. Erzeugung von synthetischen Zugriffsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importieren von Python Modulen\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shapely as shp\n",
    "import collections\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Empfangen von POIs\n",
    "\n",
    "Mithilfe des `sqlalchemy`-Moduls wird eine Verbindung zu der Datenbank aus `02_database_service` aufgebaut. In der Arbeit beschriebene POIs werden dann mittels SQL empfangen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://postgres:toor@localhost:5432/postgres')\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT geom, aeroway, amenity, building, capacity, \"isced_level\", leisure, name, opening_hours, shop, tourism\n",
    "FROM poi__points_of_interest\n",
    "WHERE shop IS NOT NULL\n",
    "   OR amenity='marketplace' OR shop='convenience' OR shop='supermarket'\n",
    "   OR amenity IN ('restaurant', 'fast_food', 'cafe', 'bar', 'pub')\n",
    "   OR tourism IS NOT NULL\n",
    "   OR amenity IN ('kindergarten', 'school', 'college', 'university', 'language_school')\n",
    "   OR amenity='toilets'\n",
    "   OR leisure='swimming_pool'\n",
    "   OR aeroway IS NOT NULL OR building='aerodrome';\n",
    "\"\"\"\n",
    "\n",
    "# Tabelle mit POIs\n",
    "poi_df = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Bestimmen von $\\lambda$ für POIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktion zur Berechnung der Zugriffsrate auf Bildungseinrichtungen wie in Tabelle $1$ (Seite $\\text{IV}$) dargestellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def educational_rate(poi, efactors):\n",
    "    if efactors['weekday'] > 5 or efactors['vacation'] or efactors['holiday']:\n",
    "        return 0\n",
    "\n",
    "    rate = 2.0\n",
    "\n",
    "    if efactors['snow'] >= 3:\n",
    "        rate -= 0.2\n",
    "    \n",
    "    if efactors['temp'] == 0 or efactors['temp'] == 4:\n",
    "        rate -= 0.2\n",
    "    \n",
    "    if 7 <= efactors['hour'] <= 9:\n",
    "        rate += 20.0\n",
    "\n",
    "    return max(0.1, rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktion zur Berechnung der Zugriffsrate auf diverse Freizeitaktivitäten wie in Tabelle $2$ (Seite $\\text{V}$) dargestellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leisure_rate(poi, efactors):\n",
    "    outdoors = poi['leisure'] in [\n",
    "        'picnic_table',\n",
    "        'garden',\n",
    "        'swimming_pool',\n",
    "        'horse_riding',\n",
    "        'bird_hide',\n",
    "        'playground',\n",
    "        'wildlife_hide',\n",
    "        'camping',\n",
    "        'park',\n",
    "        'maze',\n",
    "        'beach_resort',\n",
    "        'outdoor_seating']\n",
    "    \n",
    "    rate = 2.0\n",
    "\n",
    "    if outdoors and efactors['temp'] <= 1 or efactors['coco'] == 0 or efactors['snow'] > 1 or efactors['wspd'] >= 3:\n",
    "        rate -= 10.0\n",
    "    elif not outdoors:\n",
    "        rate += 2.0\n",
    "\n",
    "    if (efactors['holiday'] or efactors['vacation'] or efactors['weekday'] > 5) and 10 <= efactors['hour'] <= 21:\n",
    "        rate += 10.0\n",
    "    elif 12 <= efactors['hour'] <= 14 or 17 <= efactors['hour'] <= 21:\n",
    "        rate += 10.0\n",
    "\n",
    "    return max(0.1, rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktion zur Berechnung der Zugriffsrate POIs der Kategorie Einkauf & Tourismus, wie in Tabelle $3$ (Seite $\\text{VI}$) dargestellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commercial_rate(poi, efactors):\n",
    "    rate = 2.0\n",
    "\n",
    "    if poi['shop'] != None and efactors['weekday'] == 7:\n",
    "        return 0.0\n",
    "    elif poi['shop'] != None and efactors['weekday'] == 6:\n",
    "        rate += 15.0\n",
    "    elif poi['shop'] != None and 17 <= efactors['hour'] <= 19:\n",
    "        rate += 10.0\n",
    "\n",
    "\n",
    "    if poi['shop'] == None and 6 <= efactors['month'] <= 8:\n",
    "        rate += 20.0\n",
    "    elif poi['shop'] == None:\n",
    "        rate += 5.0\n",
    "\n",
    "    return max(0.1, rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktion der Berechnung der Zugriffsrate auf beliebige POIs (ordnet entsprechenden POIs eine der drei \"Unterfunktionen\" zu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_poi_prate(poi, efactors):\n",
    "    if poi['isced_level'] != None:\n",
    "        return educational_rate(poi, efactors)\n",
    "    elif poi['leisure'] != None:\n",
    "        return leisure_rate(poi, efactors)\n",
    "    elif (poi['shop'] != None and poi['shop'] != 'no') or poi['tourism'] != None:\n",
    "        return commercial_rate(poi, efactors)\n",
    "    else:\n",
    "        return 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Einlesen der Feature-Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_mapped_data = pd.read_csv('./data/agg_mapped_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Berechnung von Tiles für zugehörige POIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min-Tile: (0, 0)\n",
      "Max-Tile: (194, 103)\n",
      "Tiles total: 19982\n"
     ]
    }
   ],
   "source": [
    "def lonlat_to_tile(lon, lat, tile_size):\n",
    "    x_tile = int((lon - MIN_X_COORD) / tile_size)\n",
    "    y_tile = int((lat - MIN_Y_COORD) / tile_size)\n",
    "    return x_tile, y_tile\n",
    "\n",
    "MIN_X_COORD = 12.36749421446289\n",
    "MAX_X_COORD = 14.312163310124404\n",
    "\n",
    "MIN_Y_COORD = 51.948449733535\n",
    "MAX_Y_COORD = 52.978667577725275\n",
    "\n",
    "MIN_TILE = lonlat_to_tile(MIN_X_COORD, MIN_Y_COORD, 0.01)\n",
    "MAX_TILE = lonlat_to_tile(MAX_X_COORD, MAX_Y_COORD, 0.01)\n",
    "print(\"Min-Tile:\", MIN_TILE)\n",
    "print(\"Max-Tile:\", MAX_TILE)\n",
    "print(\"Tiles total:\", (MAX_TILE[0]-MIN_TILE[0]) * (MAX_TILE[1] - MIN_TILE[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Berechnung von Tile-Zugriffsraten\n",
    "\n",
    "Die Berechnung der Zugriffsraten für jedes Tile für jeden Satz an Feature-Daten ist der Zeitaufwendige Teil der Datengenerierung.\n",
    "Um den Prozess zu vereinfachen wurden alle 1500 Datensätze eine Zwischenspeicherung vorgenommen. Sollten Sie das Programm während des Generierens\n",
    "stoppen, so können Sie unter `./data/lambda_checkpoints_[ZAHL].pkl` den letzten Speicherpunkt (mit dem höchsten Wert für `[ZAHL]`) in die Variable `LOAD_FROM_CACHE` eintragen (Beispiel: `LOAD_FROM_CACHE = \"./data/lambda_checkpoints_4500.pkl\"`).\n",
    "Die Generierung von Zugriffsraten wird dann von diesem Punkt an gestartet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialisierung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier falls vorhanden den Dateipfad zum letzten Speicherstand eintragen\n",
    "LOAD_FROM_CACHE = None\n",
    "\n",
    "# Variablen für die Zustandsspeicherung\n",
    "poi_tiles = []\n",
    "n_mapd = len(agg_mapped_data)\n",
    "agg_tile_visit_rates = []\n",
    "data_iter = agg_mapped_data.iterrows()\n",
    "\n",
    "# Berechnung des Tiles für jeden POI\n",
    "for i, row in poi_df.iterrows():\n",
    "    xy_p = shp.from_wkb(row['geom']).centroid.xy\n",
    "    x, y = xy_p[0][0], xy_p[1][0]\n",
    "    tx, ty = lonlat_to_tile(x, y, 0.01)\n",
    "    tx = max(min(tx, MAX_TILE[0]), MIN_TILE[0])\n",
    "    ty = max(min(ty, MAX_TILE[1]), MIN_TILE[1])\n",
    "\n",
    "    poi_tiles.append((tx, ty))\n",
    "\n",
    "# Falls ein Speicherpunkt eingetragen wurden, wird dieser eingelesen\n",
    "if LOAD_FROM_CACHE:\n",
    "    with open(LOAD_FROM_CACHE, 'rb') as fp:\n",
    "        agg_tile_visit_rates = pickle.load(fp)\n",
    "    \n",
    "    # Bereits berechnete Datensätze werden übersprungen\n",
    "    for i in range(len(agg_tile_visit_rates)):\n",
    "        next(data_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datensynthese:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "tl = []\n",
    "\n",
    "for i, row in data_iter:\n",
    "    tile_visit_rates = collections.defaultdict(float)\n",
    "\n",
    "    # Berechnung der Zugriffsrate für jeden POI\n",
    "    for j, poi in poi_df.iterrows():\n",
    "         tile_visit_rates[poi_tiles[j]] += calculate_poi_prate(poi, row)\n",
    "\n",
    "    agg_tile_visit_rates.append(tile_visit_rates)\n",
    "\n",
    "    # Ausgabe des aktuellen Fortschritts alle 10 Datensätze\n",
    "    if i%10 == 0:\n",
    "        time_now = time.time()\n",
    "        time_elapsed = time_now - time_start\n",
    "        time_start = time_now\n",
    "        tl.append(time_elapsed)\n",
    "\n",
    "        avg_time_per_row = sum(tl)/len(tl) / 10\n",
    "        time_left_approx = (n_mapd-i-1) * avg_time_per_row\n",
    "        print(\"Progress: {}/{} | Took: {:.2f}s | Time Left~: {:.2f}s\".format(i+1, n_mapd, time_elapsed, time_left_approx))\n",
    "    \n",
    "    # Zwischenspeichern des Fortschritts alle 1500 Datensätze\n",
    "    if i%1500 == 0:\n",
    "        with open('./data/lambda_checkpoints_{}.pkl'.format(i), 'wb') as fp:\n",
    "            pickle.dump(agg_tile_visit_rates, fp)\n",
    "\n",
    "# Speichern der kompletten Information nach Durchlauf\n",
    "with open('./data/lambda_checkpoints_complete.pkl', 'wb') as fp:\n",
    "    pickle.dump(agg_tile_visit_rates, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Erzeugung von synthetischen Zugriffsdaten\n",
    "\n",
    "Da nun alle Zugriffsraten bestimmt wurden, werden nun mittels Poisson-Verteilungen konkrete Zugriffe bestimmt. Diese variieren, da dieser Prozess weitestgehend Zufällig ist. Um die Generierung\n",
    "des Datensatzes deterministisch zu machen, wird hier ein sogenannter `random-seed` gesetzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "synth_data = agg_mapped_data.to_dict()\n",
    "tile_access_dict = collections.defaultdict(list)\n",
    "\n",
    "for td_entry in agg_tile_visit_rates:\n",
    "    for tile, access_rate in td_entry.items():\n",
    "        tile = \";\".join([str(tile[0]), str(tile[1])])\n",
    "        tile_access_dict[tile].append(np.random.poisson(access_rate))\n",
    "\n",
    "for key in synth_data.keys():\n",
    "    synth_data[key] = list(synth_data[key].values())\n",
    "    \n",
    "synth_data.update(tile_access_dict)\n",
    "synth_data_df = pd.DataFrame(synth_data)\n",
    "synth_data_df.to_csv('./data/synth_access_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
